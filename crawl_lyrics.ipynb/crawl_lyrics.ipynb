{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여기 base_url 뒤에 곡 id 만 붙이면 가사 페이지로 넘어감\n",
    "base_url = \"https://music.naver.com/lyric/index.nhn?trackId=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여기 파일 안에 각 가수들의 곡 id 가 들어있음 (가수 이름 검색해서 나온 html파일)\n",
    "\n",
    "with open(\"tag_red.txt\", 'r') as f :\n",
    "    tag_red = f.readline()\n",
    "\n",
    "with open(\"tag_twice.txt\", 'r') as f :\n",
    "    tag_twice = f.readline()\n",
    "    \n",
    "with open(\"tag_fx.txt\", 'r') as f :\n",
    "    tag_fx = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정규표현식 이용해서 곡 id만 빼와서 list에 담기\n",
    "\n",
    "pattern_twice = re.compile(r\"\\\\&quot;([0-9]*)\\\\&quot;:\")\n",
    "pattern_red = re.compile(r\"\\\\&quot;([0-9]*)\\\\&quot;:\")\n",
    "pattern_fx = re.compile(r\"\\\\&quot;([0-9]*)\\\\&quot;:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_list = pattern_red.findall(tag_red)\n",
    "twice_list = pattern_twice.findall(tag_twice)\n",
    "fx_list = pattern_twice.findall(tag_fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20553167\n",
      "16969606\n",
      "18696405\n"
     ]
    }
   ],
   "source": [
    "f = open(\"red_velvet.txt\", \"w\")\n",
    "\n",
    "for i in red_list :\n",
    "    # base_url + i 은 완전한 주소 (곡 id i의 가사 페이지)\n",
    "    # requests.get으로 주소의 정보 가져옴\n",
    "    # text 메서드 통해서 가져온 정보 중에서 text만 빼옴\n",
    "    temphtml = requests.get(base_url + i).text\n",
    "    # text (html 파싱하기)\n",
    "    tempsoup = BeautifulSoup(temphtml, 'html.parser')\n",
    "    # 곡에 따라서 가사 없는것도 있어서 에러나길래 try and catch 함\n",
    "    # 아래에 print되어 있는거랑 base html 합쳐서 주소창에 쳐보면 가사 없는 거 확인할 수 있음\n",
    "    try :\n",
    "        # 전체 html 중에서 내가 원하는 부분 (f12 에서 너가 원하는 부분 copy selector 해서 넣으면 됨)\n",
    "        # 참고로 n th child 이런거는 안 먹히니까 이런거 크롤링 하고 싶으면 상위 태그 가져와서 iter 돌면서 크롤링해야함\n",
    "        temp = str(tempsoup.select('#lyricText')[0])\n",
    "    except :\n",
    "        print(i)\n",
    "    # 보니까 #lyricText tag는 안 지워지길래 그냥 내가 직접 지움\n",
    "    # 그냥 태그를 다 지우는걸로 하면 엔터랑 그런거 다 지워지길래 필요없는 태그만 replacegka\n",
    "    temp = temp[40:-6].replace(\"<br/>\", \"\\n\")\n",
    "    f.write(temp)\n",
    "    \n",
    "f.close()\n",
    "# 87 - 3 = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21456795\n",
      "21321706\n",
      "16136162\n",
      "16136161\n",
      "16136158\n",
      "16136159\n",
      "6131513\n"
     ]
    }
   ],
   "source": [
    "f = open(\"twice.txt\", \"w\")\n",
    "\n",
    "for i in twice_list :\n",
    "    temphtml = requests.get(base_url + i).text\n",
    "    tempsoup = BeautifulSoup(temphtml, 'html.parser')\n",
    "    try :\n",
    "        temp = str(tempsoup.select('#lyricText')[0])\n",
    "    except :\n",
    "        print(i)\n",
    "    temp = temp[40:-6].replace(\"<br/>\", \"\\n\")\n",
    "    f.write(temp)\n",
    "    \n",
    "f.close()\n",
    "# 114 - 7 = 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14831963\n",
      "14831975\n",
      "6220200\n",
      "2593265\n",
      "2171393\n",
      "2106260\n",
      "2106261\n",
      "2106262\n",
      "2106263\n",
      "2106264\n"
     ]
    }
   ],
   "source": [
    "f = open(\"fx.txt\", \"w\")\n",
    "\n",
    "for i in fx_list :\n",
    "    temphtml = requests.get(base_url + i).text\n",
    "    tempsoup = BeautifulSoup(temphtml, 'html.parser')\n",
    "    try :\n",
    "        temp = str(tempsoup.select('#lyricText')[0])\n",
    "    except :\n",
    "        print(i)\n",
    "    temp = temp[40:-6].replace(\"<br/>\", \"\\n\")\n",
    "    f.write(temp)\n",
    "    \n",
    "f.close()\n",
    "# 102 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
